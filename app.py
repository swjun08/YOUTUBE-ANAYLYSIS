import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from googleapiclient.discovery import build
import warnings
import platform

warnings.filterwarnings("ignore")

# ===================== í•œê¸€ í°íŠ¸ ì„¤ì • =====================
def set_korean_font():
    import matplotlib.font_manager as fm

    system = platform.system()

    if system == "Windows":
        font_name = "Malgun Gothic"
    elif system == "Darwin":
        font_name = "AppleGothic"
    else:  # Linux (Streamlit Cloud)
        font_dirs = ["/usr/share/fonts/truetype/nanum"]
        font_files = fm.findSystemFonts(fontpaths=font_dirs)
        for font_file in font_files:
            fm.fontManager.addfont(font_file)
        font_name = "NanumGothic"

    plt.rcParams["font.family"] = font_name
    plt.rcParams["axes.unicode_minus"] = False


set_korean_font()

# ===================== íŽ˜ì´ì§€ ì„¤ì • =====================
st.set_page_config(
    page_title="YouTube ì˜ìƒ ìƒê´€ê´€ê³„ ë¶„ì„",
    page_icon="ðŸ“Š",
    layout="wide",
)

# ===================== YouTube API ë°ì´í„° ìˆ˜ì§‘ =====================
@st.cache_data
def fetch_youtube_data(api_key, query, max_results):
    youtube = build("youtube", "v3", developerKey=api_key)

    search_response = youtube.search().list(
        q=query,
        part="id",
        type="video",
        maxResults=max_results
    ).execute()

    video_ids = [item["id"]["videoId"] for item in search_response["items"]]
    if not video_ids:
        return None

    video_response = youtube.videos().list(
        part="snippet,statistics",
        id=",".join(video_ids)
    ).execute()

    data = []
    for item in video_response["items"]:
        snippet = item["snippet"]
        stats = item["statistics"]

        data.append({
            "Video Title": snippet.get("title"),
            "Video Views": int(stats.get("viewCount", 0)),
            "Like_count": int(stats.get("likeCount", 0)),
            "comment_count": int(stats.get("commentCount", 0))
        })

    return pd.DataFrame(data)


# ===================== ë°ì´í„° ì „ì²˜ë¦¬ =====================
@st.cache_data
def load_and_process_data(data_source):
    if isinstance(data_source, pd.DataFrame):
        df = data_source.copy()
    else:
        df = pd.read_csv(data_source)

    original_size = len(df)

    df = df.rename(columns={
        "Video Title": "title",
        "Video Views": "views",
        "Like_count": "likes",
        "comment_count": "comment_count"
    })

    df = df[["title", "views", "likes", "comment_count"]]

    df = df.dropna(subset=["title"])
    for col in ["views", "likes", "comment_count"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
        df[col].fillna(df[col].median(), inplace=True)

    df["title_length"] = df["title"].str.len()

    # ì´ìƒì¹˜ ì œê±° (IQR)
    for col in ["views", "likes", "comment_count", "title_length"]:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        df = df[(df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)]

    stats = {
        "original_size": original_size,
        "final_size": len(df)
    }

    return df, stats


# ===================== ìƒê´€ê´€ê³„ =====================
def get_correlations(df):
    cols = ["title_length", "views", "likes", "comment_count"]
    return df[cols].corr()


# ===================== ë©”ì¸ ì•± =====================
def main():
    st.title("ðŸ“Š YouTube ì˜ìƒ ìƒê´€ê´€ê³„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("**YouTube API ë˜ëŠ” CSV íŒŒì¼ì„ ì´ìš©í•´ ì œëª© ê¸¸ì´ì™€ ì„±ê³¼ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤**")

    # ===================== ì‚¬ì´ë“œë°” =====================
    with st.sidebar:
        st.header("ðŸ”‘ YouTube API ì—°ë™")

        api_key = st.text_input("YouTube API Key", type="password")
        query = st.text_input("ê²€ìƒ‰ì–´", value="BTS")
        max_results = st.slider("ì˜ìƒ ê°œìˆ˜", 10, 100, 50, step=10)

        use_api = st.button("ðŸ” YouTubeì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°")

        st.markdown("---")
        uploaded_file = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])

    df = None

    # ===================== ë°ì´í„° ë¡œë”© =====================
    if use_api and api_key:
        with st.spinner("YouTube API ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
            api_df = fetch_youtube_data(api_key, query, max_results)

        if api_df is not None:
            df, stats = load_and_process_data(api_df)
            st.success("âœ… YouTube API ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

    elif uploaded_file is not None:
        with st.spinner("CSV ë°ì´í„° ë¡œë”© ì¤‘..."):
            df, stats = load_and_process_data(uploaded_file)
        st.success("âœ… CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

    else:
        st.info("ðŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ API ì‚¬ìš© ë˜ëŠ” CSV ì—…ë¡œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”")
        return

    # ===================== ê°œìš” =====================
    st.markdown("## ðŸ“ˆ ë°ì´í„° ê°œìš”")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì˜ìƒ ìˆ˜", len(df))
    col2.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{df['views'].mean():,.0f}")
    col3.metric("í‰ê·  ì¢‹ì•„ìš”", f"{df['likes'].mean():,.0f}")
    col4.metric("í‰ê·  ì œëª© ê¸¸ì´", f"{df['title_length'].mean():.1f}ìž")

    # ===================== ížˆíŠ¸ë§µ =====================
    st.markdown("## ðŸ”¥ ìƒê´€ê´€ê³„ ížˆíŠ¸ë§µ")

    corr = get_correlations(df)
    corr.columns = ["ì œëª© ê¸¸ì´", "ì¡°íšŒìˆ˜", "ì¢‹ì•„ìš” ìˆ˜", "ëŒ“ê¸€ ìˆ˜"]
    corr.index = ["ì œëª© ê¸¸ì´", "ì¡°íšŒìˆ˜", "ì¢‹ì•„ìš” ìˆ˜", "ëŒ“ê¸€ ìˆ˜"]

    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(
        corr,
        annot=True,
        cmap="RdYlBu_r",
        center=0,
        fmt=".3f",
        square=True,
        linewidths=1
    )
    st.pyplot(fig)

    # ===================== ì œëª© ê¸¸ì´ vs ì¡°íšŒìˆ˜ =====================
    st.markdown("## ðŸ“ ì œëª© ê¸¸ì´ vs ì¡°íšŒìˆ˜")

    corr_value = df["title_length"].corr(df["views"])

    fig, ax = plt.subplots(figsize=(10, 6))
    ax.scatter(df["title_length"], df["views"], alpha=0.5)
    z = np.polyfit(df["title_length"], df["views"], 1)
    p = np.poly1d(z)
    ax.plot(df["title_length"], p(df["title_length"]), "r--")

    ax.set_xlabel("ì œëª© ê¸¸ì´")
    ax.set_ylabel("ì¡°íšŒìˆ˜")
    ax.set_title(f"ìƒê´€ê³„ìˆ˜: {corr_value:.4f}")
    ax.grid(True)

    st.pyplot(fig)

    # ===================== Top ì˜ìƒ =====================
    st.markdown("## ðŸ† ì¡°íšŒìˆ˜ TOP 10")

    top10 = df.nlargest(10, "views")[["title", "title_length", "views", "likes", "comment_count"]]
    top10.columns = ["ì œëª©", "ì œëª© ê¸¸ì´", "ì¡°íšŒìˆ˜", "ì¢‹ì•„ìš”", "ëŒ“ê¸€"]
    st.dataframe(top10, use_container_width=True)


if __name__ == "__main__":
    main()
